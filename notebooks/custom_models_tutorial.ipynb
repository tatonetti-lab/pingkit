{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Custom Models Tutorial: Plug Probe Framework\n",
        "\n",
        "This notebook demonstrates how to create and use custom neural network architectures with the Plug probe framework. We'll cover:\n",
        "\n",
        "1. **Built-in Models** - Start with simple MLP probes using string specification\n",
        "2. **Custom Model Functions** - Define your own probe architectures  \n",
        "3. **Advanced Architectures** - Attention mechanisms, deep networks, etc.\n",
        "4. **Cross-Validation** - Compare different custom models\n",
        "5. **Production Pipeline** - Save, load, and deploy custom models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data1/home/kivelsons/plug-generic-probe/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (800, 512)\n",
            "Training labels shape: (800,)\n",
            "Number of classes: 4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from plug.model import fit, cross_validate, save_artifacts, load_artifacts, predict\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create some sample data\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=512,  # Simulate transformer hidden size\n",
        "    n_classes=4,\n",
        "    n_informative=256,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[00:38:28] INFO: PlugClassifier • d=512 N=640 target=5.0 ⇒ fc1=16 params=9492 (≈14.8×N)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 1. Built-in MLP Model (String Specification) ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fit: 100%|█| 20/20 [00:00<00:00, 41.29it/s, train_loss=1.1957, val_metric=0.6426\n",
            "[00:38:30] INFO: Restored best weights (val_metric 0.6426).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built-in MLP trained in 20 epochs\n",
            "Final validation metric: 0.6426\n",
            "\n",
            "=== 2. Custom Model Function ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fit: 100%|█| 20/20 [00:00<00:00, 86.50it/s, train_loss=0.1963, val_metric=0.7686\n",
            "[00:38:30] INFO: Restored best weights (val_metric 0.7686).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custom deep probe trained in 20 epochs\n",
            "Final validation metric: 0.7686\n"
          ]
        }
      ],
      "source": [
        "print(\"=== 1. Built-in MLP Model (String Specification) ===\")\n",
        "# Start with the simple built-in MLP using string specification\n",
        "mlp_model, mlp_history = fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    model=\"mlp\",  # Built-in MLP using string\n",
        "    num_classes=4,\n",
        "    n_epochs=20,\n",
        "    val_split=0.2,\n",
        "    patience=5,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=128\n",
        ")\n",
        "\n",
        "print(f\"Built-in MLP trained in {len(mlp_history)} epochs\")\n",
        "print(f\"Final validation metric: {mlp_history[-1]['val_metric']:.4f}\")\n",
        "\n",
        "print(\"\\n=== 2. Custom Model Function ===\")\n",
        "def deep_probe(input_dim, num_classes, hidden_dim=256, num_layers=3, dropout=0.5):\n",
        "    \"\"\"A deeper probe with configurable architecture.\"\"\"\n",
        "    layers = []\n",
        "    \n",
        "    # Input layer\n",
        "    layers.extend([\n",
        "        nn.Linear(input_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout)\n",
        "    ])\n",
        "    \n",
        "    # Hidden layers\n",
        "    for _ in range(num_layers - 2):\n",
        "        layers.extend([\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        ])\n",
        "    \n",
        "    # Output layer\n",
        "    layers.append(nn.Linear(hidden_dim, num_classes))\n",
        "    \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Train the custom deep probe\n",
        "deep_model, deep_history = fit(\n",
        "    X_train, y_train,\n",
        "    model=deep_probe,  # Custom model function\n",
        "    num_classes=4,\n",
        "    n_epochs=20,\n",
        "    val_split=0.2,\n",
        "    patience=5,\n",
        "    hidden_dim=128,\n",
        "    num_layers=4,\n",
        "    dropout=0.3\n",
        ")\n",
        "\n",
        "print(f\"Custom deep probe trained in {len(deep_history)} epochs\")\n",
        "print(f\"Final validation metric: {deep_history[-1]['val_metric']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[00:38:54] INFO: Artifacts saved → tutorial_outputs/deep_probe_model.pt (+ meta tutorial_outputs/deep_probe_model.json)\n",
            "[00:38:54] INFO: Loaded model ← tutorial_outputs/deep_probe_model.pt (device=cpu)\n",
            "[00:38:54] INFO: Loaded model ← tutorial_outputs/deep_probe_model.pt (device=cpu)\n",
            "[00:38:54] INFO: Predictions → tutorial_outputs/deep_probe_predictions.csv\n",
            "[00:38:54] INFO: Metrics → tutorial_outputs/deep_probe_predictions.metrics.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 3. Saving and Loading Models ===\n",
            "Model saved to: /data1/home/kivelsons/plug-generic-probe/tutorial_outputs/deep_probe_model.pt\n",
            "Model loaded successfully: Deep probe with 4 layers for classification\n",
            "\n",
            "=== 4. Making Predictions ===\n",
            "Predictions completed! Shape: (200, 5)\n",
            "Sample predictions:\n",
            "         id  prob_class_0  prob_class_1  prob_class_2  prob_class_3\n",
            "0  sample_0      0.007184      0.051992      0.937045      0.003780\n",
            "1  sample_1      0.002558      0.435386      0.190167      0.371888\n",
            "2  sample_2      0.013586      0.204972      0.002027      0.779415\n",
            "3  sample_3      0.998933      0.000481      0.000297      0.000290\n",
            "4  sample_4      0.222337      0.533917      0.014780      0.228966\n"
          ]
        }
      ],
      "source": [
        "print(\"=== 3. Saving and Loading Models ===\")\n",
        "# Save the model with custom factory for reconstruction\n",
        "weights_path, meta_path = save_artifacts(\n",
        "    deep_model,\n",
        "    path=\"tutorial_outputs/deep_probe_model\",\n",
        "    model_factory=deep_probe,\n",
        "    model_kwargs={\n",
        "        \"hidden_dim\": 128,\n",
        "        \"num_layers\": 4,\n",
        "        \"dropout\": 0.3\n",
        "    },\n",
        "    meta={\"description\": \"Deep probe with 4 layers for classification\"}\n",
        ")\n",
        "\n",
        "print(f\"Model saved to: {weights_path}\")\n",
        "\n",
        "# Test loading the model back\n",
        "loaded_model, loaded_meta = load_artifacts(\"tutorial_outputs/deep_probe_model\", device=\"cpu\")\n",
        "print(f\"Model loaded successfully: {loaded_meta['description']}\")\n",
        "\n",
        "print(\"\\n=== 4. Making Predictions ===\")\n",
        "# Create test data\n",
        "test_features_df = pd.DataFrame(X_test, columns=[f\"feature_{i}\" for i in range(X_test.shape[1])])\n",
        "test_features_df.index = [f\"sample_{i}\" for i in range(len(test_features_df))]\n",
        "test_features_df.to_csv(\"tutorial_outputs/test_features.csv\")\n",
        "\n",
        "ground_truth_df = pd.DataFrame({\"id\": test_features_df.index, \"answer\": y_test})\n",
        "ground_truth_df.to_csv(\"tutorial_outputs/ground_truth.csv\", index=False)\n",
        "\n",
        "# Make predictions with output directory\n",
        "predictions_df = predict(\n",
        "    features=\"tutorial_outputs/test_features.csv\",\n",
        "    model_path=\"tutorial_outputs/deep_probe_model\",\n",
        "    output_csv=\"deep_probe_predictions.csv\",\n",
        "    response_csv=\"tutorial_outputs/ground_truth.csv\",\n",
        "    response_col=\"answer\",\n",
        "    device=\"cpu\",\n",
        "    batch_size=1024,\n",
        "    output_dir=\"tutorial_outputs\"\n",
        ")\n",
        "\n",
        "print(f\"Predictions completed! Shape: {predictions_df.shape}\")\n",
        "print(\"Sample predictions:\")\n",
        "print(predictions_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 5. Advanced Custom Architectures ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fit:  33%|▎| 5/15 [00:00<00:00, 47.77it/s, train_loss=0.1035, val_metric=0.7272][00:39:10] INFO: Early stopping at epoch 12 (best=0.7435)\n",
            "Fit:  73%|▋| 11/15 [00:00<00:00, 50.41it/s, train_loss=0.1035, val_metric=0.7272\n",
            "[00:39:10] INFO: Restored best weights (val_metric 0.7435).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention probe trained in 12 epochs\n",
            "Final validation metric: 0.7272\n",
            "\n",
            "Model parameter counts:\n",
            "Built-in MLP: 9,492\n",
            "Deep probe: 99,204\n",
            "Attention probe: 428,420\n"
          ]
        }
      ],
      "source": [
        "print(\"=== 5. Advanced Custom Architectures ===\")\n",
        "\n",
        "def attention_probe(input_dim, num_classes, hidden_dim=256, num_heads=8, dropout=0.1):\n",
        "    \"\"\"A probe with self-attention mechanism.\"\"\"\n",
        "    \n",
        "    class AttentionProbe(nn.Module):\n",
        "        def __init__(self, input_dim, num_classes, hidden_dim, num_heads, dropout):\n",
        "            super().__init__()\n",
        "            self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "            self.attention = nn.MultiheadAttention(\n",
        "                embed_dim=hidden_dim,\n",
        "                num_heads=num_heads,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.norm = nn.LayerNorm(hidden_dim)\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim // 2, num_classes)\n",
        "            )\n",
        "            \n",
        "        def forward(self, x):\n",
        "            # Project input to hidden dimension\n",
        "            x = self.input_proj(x)  # [batch, hidden_dim]\n",
        "            \n",
        "            # Add sequence dimension for attention (treat as single token)\n",
        "            x = x.unsqueeze(1)  # [batch, 1, hidden_dim]\n",
        "            \n",
        "            # Self-attention\n",
        "            attn_out, _ = self.attention(x, x, x)\n",
        "            attn_out = self.norm(attn_out + x)  # Residual connection\n",
        "            \n",
        "            # Remove sequence dimension and classify\n",
        "            x = attn_out.squeeze(1)  # [batch, hidden_dim]\n",
        "            x = self.dropout(x)\n",
        "            return self.classifier(x)\n",
        "    \n",
        "    return AttentionProbe(input_dim, num_classes, hidden_dim, num_heads, dropout)\n",
        "\n",
        "# Train attention-based probe\n",
        "attention_model, attention_history = fit(\n",
        "    X_train, y_train,\n",
        "    model=attention_probe,\n",
        "    num_classes=4,\n",
        "    n_epochs=15,\n",
        "    val_split=0.2,\n",
        "    patience=5,\n",
        "    hidden_dim=256,\n",
        "    num_heads=4,\n",
        "    dropout=0.1,\n",
        "    learning_rate=1e-3\n",
        ")\n",
        "\n",
        "print(f\"Attention probe trained in {len(attention_history)} epochs\")\n",
        "print(f\"Final validation metric: {attention_history[-1]['val_metric']:.4f}\")\n",
        "\n",
        "# Compare model complexities\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel parameter counts:\")\n",
        "print(f\"Built-in MLP: {count_parameters(mlp_model):,}\")\n",
        "print(f\"Deep probe: {count_parameters(deep_model):,}\")\n",
        "print(f\"Attention probe: {count_parameters(attention_model):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[00:39:18] INFO: Fold 1/3 - training …\n",
            "[00:39:18] INFO: PlugClassifier • d=512 N=453 target=5.0 ⇒ fc1=16 params=9492 (≈21.0×N)\n",
            "[00:39:18] INFO: Fold 1 ep   1 | train_roc_auc 0.5638 val_roc_auc 0.5275\n",
            "[00:39:18] INFO: Fold 1 ep   2 | train_roc_auc 0.5955 val_roc_auc 0.5181\n",
            "[00:39:18] INFO: Fold 1 ep   3 | train_roc_auc 0.6204 val_roc_auc 0.5219\n",
            "[00:39:18] INFO: Fold 1 ep   4 | train_roc_auc 0.6442 val_roc_auc 0.5233\n",
            "[00:39:18] INFO: Fold 1 ep   5 | train_roc_auc 0.6612 val_roc_auc 0.5346\n",
            "[00:39:18] INFO: Fold 1 ep   6 | train_roc_auc 0.6798 val_roc_auc 0.5340\n",
            "[00:39:18] INFO: Fold 1 ep   7 | train_roc_auc 0.6975 val_roc_auc 0.5406\n",
            "[00:39:18] INFO: Fold 1 ep   8 | train_roc_auc 0.7190 val_roc_auc 0.5465\n",
            "[00:39:19] INFO: Fold 1 ep   9 | train_roc_auc 0.7360 val_roc_auc 0.5598\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 6. Cross-Validation Comparison ===\n",
            "\n",
            "Running CV for mlp...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[00:39:19] INFO: Fold 1 ep  10 | train_roc_auc 0.7585 val_roc_auc 0.5640\n",
            "[00:39:19] INFO: Fold 1 - restored best weights (val 0.5640)\n",
            "[00:39:19] INFO: Fold 1 finished - roc_auc 0.5818\n",
            "[00:39:19] INFO: Fold 2/3 - training …\n",
            "[00:39:19] INFO: PlugClassifier • d=512 N=453 target=5.0 ⇒ fc1=16 params=9492 (≈21.0×N)\n",
            "[00:39:19] INFO: Fold 2 ep   1 | train_roc_auc 0.5297 val_roc_auc 0.4625\n",
            "[00:39:19] INFO: Fold 2 ep   2 | train_roc_auc 0.5799 val_roc_auc 0.4810\n",
            "[00:39:19] INFO: Fold 2 ep   3 | train_roc_auc 0.6302 val_roc_auc 0.4908\n",
            "[00:39:19] INFO: Fold 2 ep   4 | train_roc_auc 0.6682 val_roc_auc 0.5090\n",
            "[00:39:19] INFO: Fold 2 ep   5 | train_roc_auc 0.7001 val_roc_auc 0.5181\n",
            "[00:39:19] INFO: Fold 2 ep   6 | train_roc_auc 0.7286 val_roc_auc 0.5229\n",
            "[00:39:19] INFO: Fold 2 ep   7 | train_roc_auc 0.7520 val_roc_auc 0.5202\n",
            "[00:39:19] INFO: Fold 2 ep   8 | train_roc_auc 0.7729 val_roc_auc 0.5179\n",
            "[00:39:19] INFO: Fold 2 ep   9 | train_roc_auc 0.7925 val_roc_auc 0.5181\n",
            "[00:39:19] INFO: Fold 2 ep  10 | train_roc_auc 0.8124 val_roc_auc 0.5217\n",
            "[00:39:19] INFO: Fold 2 - early stop at epoch 10 (best=0.5229)\n",
            "[00:39:19] INFO: Fold 2 - restored best weights (val 0.5229)\n",
            "[00:39:19] INFO: Fold 2 finished - roc_auc 0.4622\n",
            "[00:39:19] INFO: Fold 3/3 - training …\n",
            "[00:39:19] INFO: PlugClassifier • d=512 N=453 target=5.0 ⇒ fc1=16 params=9492 (≈21.0×N)\n",
            "[00:39:19] INFO: Fold 3 ep   1 | train_roc_auc 0.5310 val_roc_auc 0.5075\n",
            "[00:39:19] INFO: Fold 3 ep   2 | train_roc_auc 0.5699 val_roc_auc 0.5099\n",
            "[00:39:19] INFO: Fold 3 ep   3 | train_roc_auc 0.6011 val_roc_auc 0.5235\n",
            "[00:39:19] INFO: Fold 3 ep   4 | train_roc_auc 0.6313 val_roc_auc 0.5284\n",
            "[00:39:19] INFO: Fold 3 ep   5 | train_roc_auc 0.6565 val_roc_auc 0.5287\n",
            "[00:39:19] INFO: Fold 3 ep   6 | train_roc_auc 0.6788 val_roc_auc 0.5309\n",
            "[00:39:19] INFO: Fold 3 ep   7 | train_roc_auc 0.7020 val_roc_auc 0.5423\n",
            "[00:39:19] INFO: Fold 3 ep   8 | train_roc_auc 0.7250 val_roc_auc 0.5516\n",
            "[00:39:19] INFO: Fold 3 ep   9 | train_roc_auc 0.7464 val_roc_auc 0.5588\n",
            "[00:39:19] INFO: Fold 3 ep  10 | train_roc_auc 0.7674 val_roc_auc 0.5651\n",
            "[00:39:19] INFO: Fold 3 - restored best weights (val 0.5651)\n",
            "[00:39:19] INFO: Fold 3 finished - roc_auc 0.5643\n",
            "[00:39:19] INFO: CV done - overall 0.5279 | 0.7s\n",
            "[00:39:19] INFO: Fold 1/3 - training …\n",
            "[00:39:19] INFO: Fold 1 ep   1 | train_roc_auc 0.6769 val_roc_auc 0.5471\n",
            "[00:39:19] INFO: Fold 1 ep   2 | train_roc_auc 0.8262 val_roc_auc 0.5927\n",
            "[00:39:19] INFO: Fold 1 ep   3 | train_roc_auc 0.9170 val_roc_auc 0.6250\n",
            "[00:39:19] INFO: Fold 1 ep   4 | train_roc_auc 0.9702 val_roc_auc 0.6435\n",
            "[00:39:19] INFO: Fold 1 ep   5 | train_roc_auc 0.9882 val_roc_auc 0.6733\n",
            "[00:39:19] INFO: Fold 1 ep   6 | train_roc_auc 0.9948 val_roc_auc 0.6985\n",
            "[00:39:19] INFO: Fold 1 ep   7 | train_roc_auc 0.9980 val_roc_auc 0.7125\n",
            "[00:39:19] INFO: Fold 1 ep   8 | train_roc_auc 0.9993 val_roc_auc 0.7235\n",
            "[00:39:19] INFO: Fold 1 ep   9 | train_roc_auc 0.9997 val_roc_auc 0.7300\n",
            "[00:39:19] INFO: Fold 1 ep  10 | train_roc_auc 0.9999 val_roc_auc 0.7365\n",
            "[00:39:19] INFO: Fold 1 - restored best weights (val 0.7365)\n",
            "[00:39:19] INFO: Fold 1 finished - roc_auc 0.6885\n",
            "[00:39:19] INFO: Fold 2/3 - training …\n",
            "[00:39:19] INFO: Fold 2 ep   1 | train_roc_auc 0.7011 val_roc_auc 0.5575\n",
            "[00:39:19] INFO: Fold 2 ep   2 | train_roc_auc 0.8621 val_roc_auc 0.5988\n",
            "[00:39:19] INFO: Fold 2 ep   3 | train_roc_auc 0.9402 val_roc_auc 0.6398\n",
            "[00:39:19] INFO: Fold 2 ep   4 | train_roc_auc 0.9673 val_roc_auc 0.6702\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlp CV score: 0.5279\n",
            "\n",
            "Running CV for deep_probe...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[00:39:19] INFO: Fold 2 ep   5 | train_roc_auc 0.9834 val_roc_auc 0.6929\n",
            "[00:39:19] INFO: Fold 2 ep   6 | train_roc_auc 0.9939 val_roc_auc 0.7177\n",
            "[00:39:19] INFO: Fold 2 ep   7 | train_roc_auc 0.9980 val_roc_auc 0.7194\n",
            "[00:39:19] INFO: Fold 2 ep   8 | train_roc_auc 0.9994 val_roc_auc 0.7227\n",
            "[00:39:19] INFO: Fold 2 ep   9 | train_roc_auc 0.9999 val_roc_auc 0.7342\n",
            "[00:39:19] INFO: Fold 2 ep  10 | train_roc_auc 1.0000 val_roc_auc 0.7448\n",
            "[00:39:19] INFO: Fold 2 - restored best weights (val 0.7448)\n",
            "[00:39:19] INFO: Fold 2 finished - roc_auc 0.6861\n",
            "[00:39:19] INFO: Fold 3/3 - training …\n",
            "[00:39:19] INFO: Fold 3 ep   1 | train_roc_auc 0.7124 val_roc_auc 0.5418\n",
            "[00:39:19] INFO: Fold 3 ep   2 | train_roc_auc 0.8599 val_roc_auc 0.5588\n",
            "[00:39:19] INFO: Fold 3 ep   3 | train_roc_auc 0.9467 val_roc_auc 0.5891\n",
            "[00:39:20] INFO: Fold 3 ep   4 | train_roc_auc 0.9805 val_roc_auc 0.6155\n",
            "[00:39:20] INFO: Fold 3 ep   5 | train_roc_auc 0.9926 val_roc_auc 0.6336\n",
            "[00:39:20] INFO: Fold 3 ep   6 | train_roc_auc 0.9973 val_roc_auc 0.6566\n",
            "[00:39:20] INFO: Fold 3 ep   7 | train_roc_auc 0.9993 val_roc_auc 0.6658\n",
            "[00:39:20] INFO: Fold 3 ep   8 | train_roc_auc 0.9999 val_roc_auc 0.6725\n",
            "[00:39:20] INFO: Fold 3 ep   9 | train_roc_auc 1.0000 val_roc_auc 0.6842\n",
            "[00:39:20] INFO: Fold 3 ep  10 | train_roc_auc 1.0000 val_roc_auc 0.6974\n",
            "[00:39:20] INFO: Fold 3 - restored best weights (val 0.6974)\n",
            "[00:39:20] INFO: Fold 3 finished - roc_auc 0.7103\n",
            "[00:39:20] INFO: CV done - overall 0.6940 | 0.4s\n",
            "[00:39:20] INFO: Fold 1/3 - training …\n",
            "[00:39:20] INFO: Fold 1 ep   1 | train_roc_auc 0.7888 val_roc_auc 0.6104\n",
            "[00:39:20] INFO: Fold 1 ep   2 | train_roc_auc 0.9094 val_roc_auc 0.6679\n",
            "[00:39:20] INFO: Fold 1 ep   3 | train_roc_auc 0.9507 val_roc_auc 0.7023\n",
            "[00:39:20] INFO: Fold 1 ep   4 | train_roc_auc 0.9680 val_roc_auc 0.7181\n",
            "[00:39:20] INFO: Fold 1 ep   5 | train_roc_auc 0.9765 val_roc_auc 0.7221\n",
            "[00:39:20] INFO: Fold 1 ep   6 | train_roc_auc 0.9844 val_roc_auc 0.7165\n",
            "[00:39:20] INFO: Fold 1 ep   7 | train_roc_auc 0.9893 val_roc_auc 0.7154\n",
            "[00:39:20] INFO: Fold 1 ep   8 | train_roc_auc 0.9941 val_roc_auc 0.7192\n",
            "[00:39:20] INFO: Fold 1 ep   9 | train_roc_auc 0.9968 val_roc_auc 0.7187\n",
            "[00:39:20] INFO: Fold 1 - early stop at epoch 9 (best=0.7221)\n",
            "[00:39:20] INFO: Fold 1 - restored best weights (val 0.7221)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deep_probe CV score: 0.6940\n",
            "\n",
            "Running CV for attention...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[00:39:20] INFO: Fold 1 finished - roc_auc 0.6960\n",
            "[00:39:20] INFO: Fold 2/3 - training …\n",
            "[00:39:20] INFO: Fold 2 ep   1 | train_roc_auc 0.8171 val_roc_auc 0.6202\n",
            "[00:39:20] INFO: Fold 2 ep   2 | train_roc_auc 0.9133 val_roc_auc 0.6671\n",
            "[00:39:20] INFO: Fold 2 ep   3 | train_roc_auc 0.9552 val_roc_auc 0.7044\n",
            "[00:39:20] INFO: Fold 2 ep   4 | train_roc_auc 0.9721 val_roc_auc 0.7337\n",
            "[00:39:20] INFO: Fold 2 ep   5 | train_roc_auc 0.9783 val_roc_auc 0.7419\n",
            "[00:39:20] INFO: Fold 2 ep   6 | train_roc_auc 0.9836 val_roc_auc 0.7492\n",
            "[00:39:20] INFO: Fold 2 ep   7 | train_roc_auc 0.9888 val_roc_auc 0.7552\n",
            "[00:39:20] INFO: Fold 2 ep   8 | train_roc_auc 0.9938 val_roc_auc 0.7602\n",
            "[00:39:20] INFO: Fold 2 ep   9 | train_roc_auc 0.9973 val_roc_auc 0.7621\n",
            "[00:39:20] INFO: Fold 2 ep  10 | train_roc_auc 0.9990 val_roc_auc 0.7583\n",
            "[00:39:20] INFO: Fold 2 - restored best weights (val 0.7621)\n",
            "[00:39:20] INFO: Fold 2 finished - roc_auc 0.6752\n",
            "[00:39:20] INFO: Fold 3/3 - training …\n",
            "[00:39:20] INFO: Fold 3 ep   1 | train_roc_auc 0.7849 val_roc_auc 0.6054\n",
            "[00:39:20] INFO: Fold 3 ep   2 | train_roc_auc 0.9025 val_roc_auc 0.6521\n",
            "[00:39:20] INFO: Fold 3 ep   3 | train_roc_auc 0.9471 val_roc_auc 0.6874\n",
            "[00:39:20] INFO: Fold 3 ep   4 | train_roc_auc 0.9675 val_roc_auc 0.7175\n",
            "[00:39:20] INFO: Fold 3 ep   5 | train_roc_auc 0.9764 val_roc_auc 0.7234\n",
            "[00:39:20] INFO: Fold 3 ep   6 | train_roc_auc 0.9825 val_roc_auc 0.7370\n",
            "[00:39:20] INFO: Fold 3 ep   7 | train_roc_auc 0.9877 val_roc_auc 0.7461\n",
            "[00:39:20] INFO: Fold 3 ep   8 | train_roc_auc 0.9923 val_roc_auc 0.7516\n",
            "[00:39:20] INFO: Fold 3 ep   9 | train_roc_auc 0.9961 val_roc_auc 0.7488\n",
            "[00:39:20] INFO: Fold 3 ep  10 | train_roc_auc 0.9980 val_roc_auc 0.7529\n",
            "[00:39:20] INFO: Fold 3 - restored best weights (val 0.7529)\n",
            "[00:39:20] INFO: Fold 3 finished - roc_auc 0.7029\n",
            "[00:39:20] INFO: CV done - overall 0.6804 | 0.6s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attention CV score: 0.6804\n",
            "\n",
            "=== Cross-Validation Results Summary ===\n",
            "mlp             | roc_auc: 0.5279 | Time: 0.7s\n",
            "deep_probe      | roc_auc: 0.6940 | Time: 0.4s\n",
            "attention       | roc_auc: 0.6804 | Time: 0.6s\n"
          ]
        }
      ],
      "source": [
        "print(\"=== 6. Cross-Validation Comparison ===\")\n",
        "\n",
        "# Compare different models using cross-validation\n",
        "models_to_compare = [\n",
        "    (\"mlp\", {\"model\": \"mlp\"}),\n",
        "    (\"deep_probe\", {\"model\": deep_probe, \"hidden_dim\": 128, \"num_layers\": 3, \"dropout\": 0.3}),\n",
        "    (\"attention\", {\"model\": attention_probe, \"hidden_dim\": 128, \"num_heads\": 4, \"dropout\": 0.1})\n",
        "]\n",
        "\n",
        "cv_results = {}\n",
        "for model_name, model_config in models_to_compare:\n",
        "    print(f\"\\nRunning CV for {model_name}...\")\n",
        "    \n",
        "    preds, cv_summary = cross_validate(\n",
        "        X_train, y_train,\n",
        "        num_classes=4,\n",
        "        n_splits=3,  # Fewer splits for demo\n",
        "        n_epochs=10,\n",
        "        patience=3,\n",
        "        out_dir=\"tutorial_outputs/cv_results\",\n",
        "        run_name=f\"{model_name}_cv\",\n",
        "        **model_config\n",
        "    )\n",
        "    \n",
        "    cv_results[model_name] = cv_summary\n",
        "    print(f\"{model_name} CV score: {cv_summary['overall_metric']:.4f}\")\n",
        "\n",
        "# Print comparison summary\n",
        "print(\"\\n=== Cross-Validation Results Summary ===\")\n",
        "for model_name, summary in cv_results.items():\n",
        "    metric_name = summary['metric_name']\n",
        "    overall_score = summary['overall_metric']\n",
        "    total_time = summary['sec_total']\n",
        "    print(f\"{model_name:15s} | {metric_name}: {overall_score:.4f} | Time: {total_time:.1f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
